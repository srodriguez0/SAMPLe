{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We begin with a simple example of how to use BeautifulSoup to parse a downloaded html page.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(open('2014102803.html'), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We could also do this off a requested page.\n",
    "# Note this is not the same play-by-play log corresponding to the html page opened above.\n",
    "\n",
    "# import requests\n",
    "#\n",
    "# r = requests.get('http://knbr.stats.com/nba/pbp.asp?gamecode=2016102701&home=1&vis=27')\n",
    "# soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112:00NOStarting Lineup - Eric Gordon00\n"
     ]
    }
   ],
   "source": [
    "# We parse the page this linearly by traversing the tags in the html tree.\n",
    "\n",
    "firstPlayer = soup.tr.next_sibling.next_sibling\n",
    "print(firstPlayer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112:00NOStarting Lineup - Omer Asik00\n"
     ]
    }
   ],
   "source": [
    "# As with most trees, you can access the parents, siblings, and children of a node (represented by tags).\n",
    "\n",
    "secondPlayer = firstPlayer.next_sibling\n",
    "print(secondPlayer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eric Gordon\n",
      "Omer Asik\n",
      "Jrue Holiday\n",
      "Tyreke Evans\n",
      "Anthony Davis\n",
      "Nikola Vucevic\n",
      "Kyle O'Quinn\n",
      "Tobias Harris\n",
      "Elfrid Payton\n",
      "Evan Fournier\n"
     ]
    }
   ],
   "source": [
    "# We can also do parsing with the 'find' function.\n",
    "\n",
    "player = firstPlayer\n",
    "while \"Starting Lineup\" in player.text:\n",
    "    name = player.find_all(\"td\", {\"class\" : \"shsNamD\"})[2].text\n",
    "    name = name[name.find('-')+2:]\n",
    "    print(name)\n",
    "    \n",
    "    player = player.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Moving on to Selenium...\n",
    "# This module helps with things need to be loaded dynamically or when a website stores login cookies.\n",
    "# The example we will use is of scraping some product data off a Safeway website. \n",
    "\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# start chrome driver and navigate to the beer-cider page\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "driver.get(\"https://shop.safeway.com/ecom/shop-by-aisle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we show a full example of how we could scrape a page dynamically clicking & combining BeautifulSoup.\n",
    "\n",
    "# ... enter email and password & login\n",
    "enter_email = driver.find_element_by_id(\"SignIn_EmailAddress\")\n",
    "enter_email.send_keys(\"srodriguez48@ucmerced.edu\")\n",
    "enter_pass = driver.find_element_by_id(\"SignIn_Password\")\n",
    "enter_pass.send_keys(\"SAMPLe2017\")\n",
    "signIn_click = driver.find_element_by_name(\"signInButton\")\n",
    "signIn_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets define some functions for data scraping...\n",
    "# Define function for writting row.\n",
    "\n",
    "# write row to csv file\n",
    "def writer (row):\n",
    "    with open('safewayScrape.csv','a') as outfile:\n",
    "        rowWriter = csv.writer(outfile, delimiter = ',')\n",
    "        rowWriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define a function to try to load a page.\n",
    "# To see if a page is loaded, we query a specific XPATH address of the html page.\n",
    "# If we find it, we proceed; if we dont find it after 5 seconds, an exception is raised.\n",
    "\n",
    "# try to load a page\n",
    "# if we cant find queried object, search for products\n",
    "# if cant find products, refresh page and try again (max 5 times)\n",
    "def tryLoad (driver, query, i):\n",
    "    if (i == 5):\n",
    "        return i\n",
    "    wait5 = WebDriverWait(driver, 5)\n",
    "    try:\n",
    "        next_page = wait5.until(EC.presence_of_element_located((By.XPATH, query)))\n",
    "        return i\n",
    "    except TimeoutException:\n",
    "        tryFindProduct = \"//div[@class='widget widget-type-section level-2 id-productItem state-commandAdd']/div[@class='widget-content']/form\" \n",
    "        if (tryLoad(driver, tryFindProduct, 4) == 4):\n",
    "            return 6\n",
    "        print(\"Page not loaded... try \", i)\n",
    "        driver.refresh()\n",
    "        return tryLoad (driver, query, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a recursive function to go down the SafeWay category tree.\n",
    "# I find html elements by their XPATH using Selenium.\n",
    "\n",
    "# main recursive function that gets us down the category tree\n",
    "# keeps track of levels (depth of category tree), builds csv row for writing\n",
    "def goDownCat (driver, level, row):\n",
    "    if (level == 5):\n",
    "        getProducts(driver, level, row)\n",
    "        return\n",
    "\n",
    "    driver_cat_url = driver.current_url\n",
    "    query = \"//li[@class='level-\" + str(level) + \"']/a/img\"\n",
    "\n",
    "    t = tryLoad(driver, query, 0)\n",
    "    if (t == 5):\n",
    "        print(\"Error! Page would not load after 5 tries\")\n",
    "        quit()\n",
    "    elif (t == 6):\n",
    "        getProducts(driver, level, row)\n",
    "        return\n",
    "\n",
    "    cat_list_addr = driver.find_elements_by_xpath(\"//li[@class='level-\" + str(level) + \"']/a/span[@class='id-name']\")\n",
    "    cat = cat_list_addr[0]\n",
    "    category = cat.text\n",
    "    print(category)\n",
    "    cat.click()\n",
    "\n",
    "    tmpRow = row.copy()\n",
    "    tmpRow.append(category)\n",
    "    goDownCat(driver, level+1, tmpRow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scraping data with Selenium is slow.\n",
    "# We extract the html content from the Selenium webdriver object and stick it in BeautifulSoup for processing.\n",
    "# This achieves great speedup.\n",
    "\n",
    "# once products are detected on the page, scrape the necessary info and write into csv file\n",
    "def getProducts (driver, level, row):\n",
    "    if (level < 5):\n",
    "        subsubcategory = \"NA\"\n",
    "        row.append(subsubcategory)\n",
    "    if (level < 4):\n",
    "        subcategory = \"NA\"\n",
    "        row.append(subcategory)\n",
    "\n",
    "    query = \"//div[@class='widget widget-type-section level-2 id-productItem state-commandAdd']/div[@class='widget-content']/form\" \n",
    "    tryLoad (driver, query, 0)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    product_name_list = [x.find(\"span\").text for x in [y.find(\"div\", {\"class\" : \"widget-header\"}) for y in soup.find_all(\"div\", {\"class\" : \"widget widget-type-section level-2 id-productItem state-commandAdd\"})]]\n",
    "    product_content_list = [x.find(\"form\") for x in [y.find(\"div\", {\"class\" : \"widget-content\"}) for y in soup.find_all(\"div\", {\"class\" : \"widget widget-type-section level-2 id-productItem state-commandAdd\"})]]\n",
    "    for prod in range(0, len(product_name_list)):\n",
    "        writeRow = row.copy()\n",
    "\n",
    "        product_content = product_content_list[prod]\n",
    "\n",
    "        product_id = product_content.find(\"input\", {\"id\" : \"Id\"}).get(\"value\")\n",
    "        product_name = product_name_list[prod]\n",
    "        product_pic = \"https://shop.safeway.com\" + product_content.find(\"div\", {\"class\" : \"id-image\"}).find(\"img\").get(\"data-sdc-src-state-ui-richinfo\")\n",
    "\n",
    "        product_price_desc = product_content.find(\"span\", {\"class\" : \"id-priceDescription\"}).text\n",
    "        product_price_desc = product_price_desc[(product_price_desc.find(\"(\")+1):product_price_desc.find(\")\")]\n",
    "        product_price = product_content.find(\"input\", {\"id\" : \"Price\"}).get(\"value\")\n",
    "        if (product_price.find(\"/\") > -1):\n",
    "            product_price_desc = product_price.lower()\n",
    "            product_price = \"NA\"\n",
    "\n",
    "        try:\n",
    "            product_sale_desc = product_content.find(\"div\", {\"class\" : \"id-promo\"}).find(\"span\", {\"class\" : \"id-text\"}).text\n",
    "            product_sale_desc = ' '.join(product_sale_desc.split(\"\\n\"))\n",
    "        except AttributeError:\n",
    "            product_sale_desc = \"NA\"\n",
    "        try:\n",
    "            product_sale_end_date = product_content.find(\"span\", {\"class\" : \"id-endDate\"}).text\n",
    "            product_sale_end_date = product_sale_end_date[(product_sale_end_date.find(\"through \")+8):(product_sale_end_date.find(\")\"))]\n",
    "        except AttributeError:\n",
    "            product_sale_end_date = \"NA\"\n",
    "\n",
    "        product_measure = product_content.find(\"input\", {\"id\" : \"MeasureType\"}).get(\"value\").strip()\n",
    "\n",
    "        writeRow.insert(0, product_id)\n",
    "        writeRow = np.concatenate((writeRow, [product_name, product_pic, product_price, product_sale_desc, product_sale_end_date, product_price_desc, product_measure]), axis=0)\n",
    "\n",
    "        print(writeRow)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby Care\n",
      "Baby Accessories\n",
      "Bottles & Nursing\n",
      "['960078852' 'Baby Care' 'Baby Accessories' 'Bottles & Nursing'\n",
      " 'Avent Bottle Natural 9 Ounce - Each'\n",
      " 'https://shop.safeway.com/productimages/200x200/960078852_200x200.jpg'\n",
      " '12.39' 'NA' 'NA' '$12.39/each' 'Ea']\n",
      "['960056487' 'Baby Care' 'Baby Accessories' 'Bottles & Nursing'\n",
      " 'Gerber First Essentials Bottles Silicone Medium Flow 9 Ounce Months Plus - 3 Count'\n",
      " 'https://shop.safeway.com/productimages/200x200/960056487_200x200.jpg'\n",
      " '5.59' 'NA' 'NA' '$1.86/count' 'Ct']\n",
      "['960013569' 'Baby Care' 'Baby Accessories' 'Bottles & Nursing'\n",
      " 'Lansinoh Breastmilk Storage Bags - 50 Count'\n",
      " 'https://shop.safeway.com/productimages/200x200/960013569_200x200.jpg'\n",
      " '13.49' 'NA' 'NA' '$0.27/count' 'Ct']\n",
      "['165450127' 'Baby Care' 'Baby Accessories' 'Bottles & Nursing'\n",
      " 'Lansinoh Disposable Nursing Pads - 60 Count'\n",
      " 'https://shop.safeway.com/productimages/200x200/165450127_200x200.jpg'\n",
      " '11.19' 'NA' 'NA' '$0.19/count' 'Ct']\n",
      "['960123711' 'Baby Care' 'Baby Accessories' 'Bottles & Nursing'\n",
      " 'Munchkin Brush Set Cleaning - Each'\n",
      " 'https://shop.safeway.com/productimages/200x200/960123711_200x200.jpg'\n",
      " '4.49' 'Safeway Club Price: $4.49SAVE up to: $0.50' '02/21/2017'\n",
      " '$4.49/each' 'Ea']\n",
      "['165450553' 'Baby Care' 'Baby Accessories' 'Bottles & Nursing'\n",
      " 'Playtex Drop-Ins Disposable Liners Pre-Sterilized 8-10 Ounce - 100 Count'\n",
      " 'https://shop.safeway.com/productimages/200x200/165450553_200x200.jpg'\n",
      " '12.39' 'NA' 'NA' '$0.12/count' 'Ct']\n"
     ]
    }
   ],
   "source": [
    "# Start experiment...\n",
    "goDownCat(driver, 2, [])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
